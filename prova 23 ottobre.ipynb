{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\GitHub\\hsim\\hsim\\core\\core.py:57: UserWarning: Bypassing \"None\" callbakcs\n",
      "  warn('Bypassing \"None\" callbakcs')\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from sys import path\n",
    "path.append('../')\n",
    "import hsim.core.pymulate as pym\n",
    "from hsim.core.chfsm import CHFSM, Transition, State\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from simpy import AnyOf\n",
    "from copy import deepcopy\n",
    "from random import choices,seed,normalvariate, expovariate\n",
    "from hsim.core.stores import Store, Box       \n",
    "from scipy import stats\n",
    "import dill\n",
    "import hsim.core.utils as utils\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from collections import deque \n",
    "import math\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def plot_service_times(service_times_log):\n",
    "    df = pd.DataFrame(service_times_log)\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, action_dim,max_time):\n",
    "        self.state_dim = state_dim\n",
    "        self.dim = action_dim\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon =1.0\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.epsilon_min = 0.5\n",
    "        self.model = DQN(state_dim, action_dim)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
    "        self.criterion = nn.MSELoss() \n",
    "        self.accumulated_rewards = list([])#deque(maxlen=10000)\n",
    "        self.current_time=0\n",
    "        self.max_time= max_time\n",
    "        self.episode_count = 0\n",
    "        self.previous_total_reward = float('inf')\n",
    "        self.rewards_window = deque(maxlen=100)\n",
    "        self.sequence_length = action_dim\n",
    "        self.current_sequence = []\n",
    "        self.final=0\n",
    "        \n",
    "    def save_model(self):\n",
    "            torch.save({\n",
    "                'model_state_dict': self.model.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'epsilon': self.epsilon,\n",
    "                'memory': list(self.memory),\n",
    "                'previous_total_reward': self.previous_total_reward # Salva la memoria come lista\n",
    "            }, 'dqn_model.pth')\n",
    "            print(\"Model saved to dqn_model.pth\")\n",
    "    \n",
    "    def load_model(self):\n",
    "        try:\n",
    "            checkpoint = torch.load('dqn_model.pth')\n",
    "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            self.epsilon = checkpoint['epsilon']\n",
    "            # print(f'questa è epsilon {self.epsilon}')\n",
    "            self.memory = deque(checkpoint['memory'], maxlen=10000)\n",
    "            self.previous_total_reward = checkpoint.get('previous_total_reward',float('inf') )  # Carica la memoria\n",
    "            self.model.train()  # Imposta il modello in modalità di addestramento\n",
    "            #self.model.eval()  # Imposta il modello in modalità di valutazione\n",
    "            print(\"Model loaded from dqn_model.pth\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No saved model found, starting with a new model\")\n",
    "    \n",
    "    # def update_last_transition(self):\n",
    "    #     if not self.memory:\n",
    "    #         print(\"Memory is empty, no transition to update.\")\n",
    "    #         return\n",
    "        \n",
    "    #     final_reward = self.calculate_final_reward()\n",
    "    #     # print(f'il reward finale è: {final_reward}')\n",
    "    #     # state=lab.gate.get_state(lab.b_df)\n",
    "    #     # self.memory.append((state, action, final_reward, next_state, done))\n",
    "        \n",
    "    #     # Estrai l'ultima transizione dalla memoria\n",
    "    #     last_transition = self.memory[-1]\n",
    "    #     last_transition = list(last_transition)\n",
    "    #     last_transition[2]=final_reward\n",
    "    #     last_transition[4]=True\n",
    "    #     last_transition=tuple(last_transition)\n",
    "    #     self.memory[-1]=last_transition\n",
    "    #     # Verifica che la transizione abbia la struttura corretta\n",
    "    #     # if len(last_transition) != 5:\n",
    "    #     #     print(\"Invalid transition format.\")\n",
    "    #     #     return\n",
    "        \n",
    "    #     # last_state, last_action, last_reward, last_next_state, last_done = last_transition\n",
    "        \n",
    "    #     # Aggiorna l'ultima transizione con il reward finale e imposta done a True\n",
    "    #     # modified_transition = (last_state, last_action, final_reward, last_next_state, True)\n",
    "    #     # self.memory[-1] = modified_transition\n",
    "        \n",
    "    #     # Pulisce le ricompense accumulate\n",
    "    #     self.accumulated_rewards.clear()\n",
    "        \n",
    "    #     # Salva il modello\n",
    "    #     self.save_model()\n",
    "\n",
    "\n",
    "    def update_last_transition(self):\n",
    "        if not self.memory:\n",
    "            print(\"Memory is empty, no transition to update.\")\n",
    "            return\n",
    "        \n",
    "        # Trova l'ultimo episodio\n",
    "        last_episode = []\n",
    "        for transition in reversed(self.memory):\n",
    "            last_episode.insert(0, transition)\n",
    "            if transition[4]:  # Se done è True\n",
    "                break\n",
    "        \n",
    "        if not last_episode:\n",
    "            print(\"No complete episode found in memory.\")\n",
    "            return\n",
    "        \n",
    "        final_reward = self.calculate_final_reward()\n",
    "        \n",
    "        # Aggiorna i reward delle transizioni nell'episodio\n",
    "        try:\n",
    "            for t in reversed(range(len(last_episode))):\n",
    "                state, action, reward, next_state, done = last_episode[t]\n",
    "                if t == len(last_episode) - 1:\n",
    "                    last_episode[t] = (state, action, final_reward, next_state, True)\n",
    "                else:\n",
    "                    final_reward = reward + self.gamma * final_reward\n",
    "                    last_episode[t] = (state, action, final_reward, next_state, done)\n",
    "        except IndexError as e:\n",
    "            print(f\"IndexError encountered: {e}\")\n",
    "            return\n",
    "        \n",
    "        # Rimuovi le transizioni dell'ultimo episodio dalla memoria\n",
    "        for _ in range(len(last_episode)):\n",
    "            self.memory.pop()\n",
    "        \n",
    "        # Aggiungi le transizioni aggiornate alla memoria\n",
    "        self.memory.extend(last_episode)\n",
    "        \n",
    "        # Pulisce le ricompense accumulate\n",
    "        self.accumulated_rewards.clear()\n",
    "        \n",
    "        # Salva il modello\n",
    "        self.save_model()\n",
    "    \n",
    "    def isdone(self,env):\n",
    "        if env.now >= self.max_time:\n",
    "            print(\"Simulation finished\")\n",
    "            # self.save_model()\n",
    "            return True\n",
    "        return False\n",
    "    def get_dimensions(self):\n",
    "        num_rows = len(self.memory)\n",
    "        num_columns = 0\n",
    "\n",
    "        if num_rows > 0:\n",
    "            first_sequence = self.memory[0]\n",
    "            if len(first_sequence) > 0:\n",
    "                first_transition = first_sequence[0]\n",
    "                num_columns = len(first_transition)\n",
    "\n",
    "        return num_rows, num_columns\n",
    "            \n",
    "    # def remember(self, state, action, reward, next_state, done):\n",
    "    #     state = np.array(state)\n",
    "    #     next_state = np.array(next_state)\n",
    "    #     state = np.nan_to_num(state, nan=9999)\n",
    "    #     next_state = np.nan_to_num(next_state, nan=9999)\n",
    "    #     # print(f\"State shape: {state.shape}\")\n",
    "    #     # print(f\"Next state shape: {next_state.shape}\")\n",
    "    #     # print(f\"Action: {action}\")\n",
    "    #     # print(f\"Reward: {reward}\")\n",
    "    #     # print(f\"Done: {done}\")\n",
    "    #     # Controllo delle transizioni valide\n",
    "    #     if state is None or action is None or reward is None or next_state is None:\n",
    "    #         print(\"Invalid entry detected, skipping insertion\")\n",
    "    #         return\n",
    "        \n",
    "    #     self.accumulated_rewards.append(reward)\n",
    "    #     transition = (state, action, reward, next_state, done)\n",
    "    #     self.current_sequence.append(transition)\n",
    "    \n",
    "    #     if len(self.current_sequence) == self.sequence_length:\n",
    "    #         # Assicurati che le sequenze vengano salvate correttamente nella memoria\n",
    "    #         self.memory.append(tuple(self.current_sequence))\n",
    "    #         self.current_sequence = []\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        state = np.array(state)\n",
    "        next_state = np.array(next_state)\n",
    "        state = np.nan_to_num(state, nan=9999)\n",
    "        next_state = np.nan_to_num(next_state, nan=9999)\n",
    "        \n",
    "        # Controllo delle transizioni valide\n",
    "        if state is None or action is None or reward is None or next_state is None:\n",
    "            print(\"Invalid entry detected, skipping insertion\")\n",
    "            return\n",
    "        \n",
    "        self.accumulated_rewards.append(reward)\n",
    "        transition = (state, action, reward, next_state, done)\n",
    "        self.memory.append(transition)\n",
    "    class ReplayBuffer:\n",
    "        def __init__(self, capacity, sequence_length):\n",
    "            self.capacity = capacity\n",
    "            self.memory = deque(maxlen=capacity)\n",
    "            self.sequence_length = sequence_length\n",
    "\n",
    "        def push(self, sequence):\n",
    "            \"\"\"Save a sequence of transitions\"\"\"\n",
    "            self.memory.append(sequence)\n",
    "\n",
    "        def sample(self, batch_size):\n",
    "            \"\"\"Sample a batch of sequences\"\"\"\n",
    "            sequences = random.sample(self.memory, batch_size)\n",
    "            return sequences\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.memory)\n",
    "        \n",
    "    def act(self, state, type_col_index, entity_col_index):\n",
    "        if isinstance(state, np.ndarray):\n",
    "            state = np.nan_to_num(state, nan=9999)\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                # Filtra le righe dove 'type' è 0\n",
    "                filtered_state = state[state[:, type_col_index] == 0]\n",
    "                # print(f'filtered_state shape {filtered_state.shape}')\n",
    "                if filtered_state.size > 0:\n",
    "                    selected_value=random.choice(filtered_state[:, entity_col_index].tolist())\n",
    "                    for i in range(len(filtered_state)):\n",
    "                        if state[i][entity_col_index] == selected_value:\n",
    "                            # print(i)\n",
    "                            return i\n",
    "                else:\n",
    "                    i=-1\n",
    "                    return i\n",
    "            else:\n",
    "                # Usa il modello per predire i Q-values e seleziona l'azione con il valore massimo\n",
    "                # print(\"EXPLOIT\")\n",
    "                # print(state.shape)\n",
    "                state_tensor = torch.FloatTensor(state)\n",
    "                q_values = self.model(state_tensor)\n",
    "                max_index=int(np.argmax(q_values.detach().numpy()[0]))\n",
    "                # print(f\"Max index: {max_index}\")\n",
    "                if max_index < 0 or max_index > len(state):\n",
    "                    i=-1\n",
    "                    return i\n",
    "    \n",
    "                return max_index\n",
    "        else:\n",
    "            print(\"State is not a NumPy array\")\n",
    "            return None\n",
    "        \n",
    "    \n",
    "    def get_reward(self, state,colonne,action,flag,done):\n",
    "                # Verifica che state sia un array NumPy\n",
    "        if not isinstance(state, np.ndarray):\n",
    "            raise ValueError(\"state deve essere un array NumPy\")\n",
    "\n",
    "        # Verifica che columns sia un array NumPy\n",
    "        if not isinstance(colonne, np.ndarray):\n",
    "            raise ValueError(\"columns deve essere un array NumPy\")\n",
    "        if action is None and flag==0:\n",
    "            reward= -10\n",
    "        if action is None and flag==1:\n",
    "            reward=0\n",
    "        if action is not None:\n",
    "            reward=0\n",
    "        try:\n",
    "            time_out_index = np.where(colonne == 'timeOut')[0][0]\n",
    "            time_in_index = np.where(colonne == 'timeIn')[0][0]\n",
    "        except IndexError:\n",
    "            raise ValueError(\"columns deve contenere 'timeOut' e 'timeIn'\")\n",
    "        state[:, time_in_index] = np.nan_to_num(state[:, time_in_index], nan=9999)\n",
    "        \n",
    "        state[:, time_out_index] = np.nan_to_num(state[:, time_out_index], nan=9999)\n",
    "        \n",
    "        max_time_out = np.nanmax(state[:, time_out_index])\n",
    "        min_time_in = np.nanmin(state[:, time_in_index])\n",
    "        # makespan = np.nanmax(state[:, time_out_index]) - np.nanmin(state[:, time_in_index])\n",
    "        if max_time_out == 9999:\n",
    "            valid_times_out = state[:, time_out_index][state[:, time_out_index] != 9999]\n",
    "            if len(valid_times_out) > 0:\n",
    "                max_time_out = np.nanmax(valid_times_out)\n",
    "                # print(f\"Max time out: {max_time_out}\")\n",
    "            else:\n",
    "                # print(\"non ci sono tempi diversi\")\n",
    "                max_time_out = 0\n",
    "        # print(max_time_out)\n",
    "        makespan = max_time_out - min_time_in\n",
    "        self.final = -makespan\n",
    "            # print(f\"Makespan: {makespan}\")\n",
    "            # if makespan == 0:\n",
    "            #     reward = 0\n",
    "            #     # print(\"Makespan is 0\")\n",
    "            # else:\n",
    "            #     reward = - makespan\n",
    "        return reward\n",
    "    def calculate_final_reward(self):\n",
    "        final_reward = self.final\n",
    "        print(f\"Final reward: {final_reward}\")\n",
    "        if lab.gate.Store.items:\n",
    "            print(\"Store is not empty, penalizing\")\n",
    "            penalty = 500\n",
    "            final_reward -= penalty\n",
    "        return final_reward\n",
    "\n",
    "    # def replay(self, batch_size):\n",
    "    #     if len(self.memory) < batch_size:\n",
    "    #         print(\"Not enough samples in memory to replay.\")\n",
    "    #         return \n",
    "    #     minibatch = random.sample(self.memory, batch_size)\n",
    "\n",
    "    #     for sequence in minibatch:\n",
    "    #         if sequence is None or len(sequence) != self.sequence_length:\n",
    "    #             print(\"Invalid sequence detected, skipping sequence\")\n",
    "    #             continue\n",
    "            \n",
    "    #         try:\n",
    "    #             states, actions, rewards, next_states, dones = zip(*sequence)\n",
    "    #         except TypeError as e:\n",
    "    #             print(f\"Error unpacking sequence: {e}\")\n",
    "    #             continue\n",
    "            \n",
    "    #         # Verifica che tutti gli stati e i prossimi stati abbiano la stessa forma\n",
    "    #         state_shapes = [state.shape for state in states]\n",
    "    #         next_state_shapes = [next_state.shape for next_state in next_states]\n",
    "            \n",
    "    #         if len(set(state_shapes)) > 1 or len(set(next_state_shapes)) > 1:\n",
    "    #             print(\"Inconsistent state shapes detected, skipping sequence\")\n",
    "    \n",
    "            \n",
    "    #             print(f\"States shape: {state_shapes}\")\n",
    "    #             print(f\"Next states shape: {next_state_shapes}\")\n",
    "            \n",
    "    #         try:\n",
    "    #             states = torch.FloatTensor(np.nan_to_num(np.array(states), nan=9999))\n",
    "    #             next_states = torch.FloatTensor(np.nan_to_num(np.array(next_states), nan=9999))\n",
    "    #             actions = torch.LongTensor(actions)\n",
    "    #             rewards = torch.FloatTensor(rewards)\n",
    "    #             dones = torch.FloatTensor(dones)\n",
    "    #         except ValueError as e:\n",
    "    #             print(f\"Error converting to tensors: {e}\")\n",
    "    #             continue\n",
    "            \n",
    "    #         print(f\"States tensor shape: {states.shape}\")\n",
    "    #         print(f\"Next states tensor shape: {next_states.shape}\")\n",
    "            \n",
    "    #         targets = rewards.clone()\n",
    "    #         non_final_mask = (dones == 0)\n",
    "    #         non_final_next_states = next_states[non_final_mask]\n",
    "            \n",
    "    #         if len(non_final_next_states) > 0:\n",
    "    #             next_q_values = self.model(non_final_next_states).max(1)[0].detach()\n",
    "    #             targets[non_final_mask] += self.gamma * next_q_values\n",
    "            \n",
    "    #         final_reward = rewards[-1]\n",
    "    #         for t in reversed(range(len(rewards))):\n",
    "    #             if t == len(rewards) - 1:\n",
    "    #                 targets[t] = final_reward\n",
    "    #             else:\n",
    "    #                 targets[t] += final_reward * (self.gamma ** (len(rewards) - 1 - t))\n",
    "            \n",
    "    #         q_values = self.model(states).gather(1, actions.unsqueeze(1)).squeeze(1)\n",
    "            \n",
    "    #         self.optimizer.zero_grad()\n",
    "    #         loss = self.criterion(q_values, targets)\n",
    "    #         loss.backward()\n",
    "    #         self.optimizer.step()\n",
    "\n",
    "    #     if self.epsilon > self.epsilon_min:\n",
    "    #         self.epsilon *= self.epsilon_decay\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            print(\"Not enough samples in memory to replay.\")\n",
    "            return \n",
    "        \n",
    "        # Trova gli indici degli episodi completi\n",
    "        episode_indices = []\n",
    "        current_episode = []\n",
    "        for idx, transition in enumerate(self.memory):\n",
    "            current_episode.append(transition)\n",
    "            if transition[4]:  # Se done è True\n",
    "                episode_indices.append(current_episode)\n",
    "                current_episode = []\n",
    "        \n",
    "        if len(episode_indices) < batch_size:\n",
    "            print(\"Not enough episodes in memory to replay.\")\n",
    "            return\n",
    "        \n",
    "        # Campiona batch_size episodi completi\n",
    "        minibatch = random.sample(episode_indices, batch_size)\n",
    "        \n",
    "        for episode in minibatch:\n",
    "            try:\n",
    "                states, actions, rewards, next_states, dones = zip(*episode)\n",
    "            except TypeError as e:\n",
    "                print(f\"Error unpacking episode: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Verifica che tutti gli stati e i prossimi stati siano array numpy\n",
    "            if not all(isinstance(state, np.ndarray) for state in states):\n",
    "                print(\"Inconsistent state types detected, skipping episode\")\n",
    "                continue\n",
    "            if not all(isinstance(next_state, np.ndarray) for next_state in next_states):\n",
    "                print(\"Inconsistent next_state types detected, skipping episode\")\n",
    "                continue\n",
    "            \n",
    "            # Verifica che tutti gli stati e i prossimi stati abbiano lo stesso numero di colonne\n",
    "            num_columns = states[0].shape[1]\n",
    "            if not all(state.shape[1] == num_columns for state in states):\n",
    "                print(\"Inconsistent number of columns in states, skipping episode\")\n",
    "                continue\n",
    "            if not all(next_state.shape[1] == num_columns for next_state in next_states):\n",
    "                print(\"Inconsistent number of columns in next_states, skipping episode\")\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                states = [torch.FloatTensor(np.nan_to_num(state, nan=9999)) for state in states]\n",
    "                next_states = [torch.FloatTensor(np.nan_to_num(next_state, nan=9999)) for next_state in next_states]\n",
    "                actions = torch.LongTensor(actions)\n",
    "                rewards = torch.FloatTensor(rewards)\n",
    "                dones = torch.FloatTensor(dones)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting to tensors: {e}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"States tensor shapes: {[state.shape for state in states]}\")\n",
    "            print(f\"Next states tensor shapes: {[next_state.shape for next_state in next_states]}\")\n",
    "            \n",
    "            targets = rewards.clone()\n",
    "            non_final_mask = (dones == 0)\n",
    "            non_final_next_states = [next_states[i] for i in range(len(next_states)) if non_final_mask[i]]\n",
    "            \n",
    "            if len(non_final_next_states) > 0:\n",
    "                next_q_values = torch.stack([self.model(next_state).max(1)[0].detach() for next_state in non_final_next_states])\n",
    "                targets[non_final_mask] += self.gamma * next_q_values\n",
    "            \n",
    "            final_reward = rewards[-1]\n",
    "            for t in reversed(range(len(rewards))):\n",
    "                if t == len(rewards) - 1:\n",
    "                    targets[t] = final_reward\n",
    "                else:\n",
    "                    targets[t] += final_reward * (self.gamma ** (len(rewards) - 1 - t))\n",
    "            \n",
    "            q_values = torch.stack([self.model(state).gather(1, actions[i].unsqueeze(0)).squeeze(0) for i, state in enumerate(states)])\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.criterion(q_values, targets)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "        \n",
    "class Entity:\n",
    "    _id_counter=0\n",
    "    def __init__(self,ID=None):\n",
    "        if ID is None:\n",
    "            self.ID = Entity._id_counter\n",
    "            Entity._id_counter += 1\n",
    "            # print(f\"sto creando un Entity ID: {self.ID}\")\n",
    "        else:\n",
    "            self.ID = ID\n",
    "        self.rework = False\n",
    "        self.serviceTime = dict()\n",
    "        # self.pt['M3'] = 1\n",
    "\n",
    "    def reset_id_counter():\n",
    "        Entity._id_counter = 0\n",
    "    @property\n",
    "    def require_robot(self):\n",
    "        if self.serviceTime['robot']>0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    @property\n",
    "    def ok(self):\n",
    "        return not (self.rework and self.require_robot)\n",
    "    def done(self):\n",
    "        self.rework = False\n",
    "                \n",
    "class LabServer(pym.Server):\n",
    "    def __init__(self,env,name=None,serviceTime=None,serviceTimeFunction=None):\n",
    "        self.controller = None\n",
    "        # serviceTime = 10\n",
    "        super().__init__(env,name,serviceTime,serviceTimeFunction)\n",
    "    def calculateServiceTime(self,entity=None,attribute='serviceTime'):\n",
    "        if not entity.ok:\n",
    "            return 20 #3.5 ### qua andrà messo 10/20 volte maggiore degli altri processing time?\n",
    "        else:\n",
    "            print(\"service time\")\n",
    "            print(super().calculateServiceTime(entity,attribute))\n",
    "            return super().calculateServiceTime(entity,attribute)\n",
    "    def completed(self):\n",
    "        if self.var.entity.ok:\n",
    "            self.controller.Messages.put(self.name)\n",
    "    T2=Transition(pym.Server.Working, pym.Server.Blocking, lambda self: self.env.timeout(self.calculateServiceTime(self.var.entity)), action = lambda self: self.completed())\n",
    "    T3=Transition(pym.Server.Blocking, pym.Server.Starving, lambda self: self.Next.put(self.var.entity),action=lambda self: [self.var.request.confirm(), self.sm.var.entity.done() if self.sm._name=='robot' else None])\n",
    "\n",
    "def plot_service_times(service_times_log):\n",
    "    df = pd.DataFrame(service_times_log)\n",
    "    df.plot(kind='bar', stacked=True, figsize=(10, 6))\n",
    "    plt.xlabel('Entity')\n",
    "    plt.ylabel('Service Time')\n",
    "    plt.title('Service Times of Entities')\n",
    "    plt.legend(title='Service Stages')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class Terminator(pym.Terminator):\n",
    "    def __init__(self, env, capacity=np.inf):\n",
    "        super().__init__(env, capacity)\n",
    "        self.controller = None\n",
    "        self.register = list()\n",
    "    def completed(self):\n",
    "        if not self.trigger.triggered:\n",
    "            self.trigger.succeed()\n",
    "    def put(self,item):\n",
    "        self.register.append(self._env.now)\n",
    "        self.controller.Messages.put('terminator')\n",
    "        return super().put(item)\n",
    "    def subscribe(self,item):\n",
    "        self.register.append(self._env.now)\n",
    "        self.controller.Messages.put('terminator')\n",
    "        return super().subscribe(item)\n",
    "class Gate(CHFSM):\n",
    "    def __init__(self,env,statedim,actiondim,max_time):\n",
    "        self.real = True\n",
    "        self.default_request_count = 0\n",
    "        self.capacity = 30 #check se è giusto 40 o 30 come era prima\n",
    "        self.lab = None\n",
    "        self.initialWIP = 12\n",
    "        self.targetWIP = 12\n",
    "        self.request = None\n",
    "        self.message = env.event()\n",
    "        self.WIP = 0\n",
    "        self.WIPlist = list()\n",
    "        self.dones=False \n",
    "        self.training_step=0\n",
    "        self.dqn_agent = DQNAgent(state_dim=statedim, action_dim=actiondim,max_time=max_time)\n",
    "        self.dqn_agent.load_model()\n",
    "        self.step_count=0\n",
    "        self.replay_frequency=10\n",
    "        # self.count=len(b)\n",
    "        super().__init__(env) #prima era in fondo ai self\n",
    "# # #AGGIUNTA\n",
    "    def concatenate_state_dataframes(self, batch_df, machine_df):\n",
    "        batch_df['type'] = 0  # 0 per batch\n",
    "        machine_df['type'] = 1  # 1 per macchina\n",
    "        dfi= pd.concat([batch_df, machine_df], axis=0, sort=False).reset_index(drop=True)\n",
    "        dfi.to_excel('dfi.xlsx')\n",
    "        return dfi\n",
    "\n",
    "    def convertdataframe(self,df,flag=True):\n",
    "        mapping = {\n",
    "            \"front\": 1,\n",
    "            \"drill\": 2,\n",
    "            \"robot\": 3,\n",
    "            \"camera\": 4,\n",
    "            \"back\": 5,\n",
    "            \"press\": 6,\n",
    "            \"manual\": 7\n",
    "        }\n",
    "        df[\"ResourceName\"] = df[\"ResourceName\"].map(mapping)\n",
    "\n",
    "        mapping2 = {\n",
    "            \"Working\": 1,\n",
    "            \"Blocking\": 2,\n",
    "            \"Starving\": 3\n",
    "        }  \n",
    "        df[\"StateName\"] = df[\"StateName\"].map(mapping2)\n",
    "        df[\"Entity\"] = df[\"id\"]\n",
    "        \n",
    "        # filtered_df = df[df[\"type\"] == 0]\n",
    "\n",
    "        # # Verifica e conversione della colonna \"id\" se è di tipo float\n",
    "        # if filtered_df[\"id\"].dtype == float:\n",
    "        #     df.loc[df[\"type\"] == 0, \"id\"] = df.loc[df[\"type\"] == 0, \"id\"].astype(int)\n",
    "\n",
    "        # # Verifica e conversione della colonna \"Entity\" se è di tipo float\n",
    "        # if filtered_df[\"Entity\"].dtype == float:\n",
    "        #     df.loc[df[\"type\"] == 0, \"Entity\"] = df.loc[df[\"type\"] == 0, \"Entity\"].astype(int)\n",
    "        \n",
    "        df.to_excel('conversionenumpy.xlsx')\n",
    "        data_array=df.to_numpy()\n",
    "        column_names = df.columns.to_numpy()\n",
    "\n",
    "        # print(column_names)\n",
    "        if flag:\n",
    "            return data_array\n",
    "        else:\n",
    "            return data_array, column_names\n",
    "\n",
    "    \n",
    "    \n",
    "    def filtro(self,val):\n",
    "        return lambda item: item == val\n",
    "    \n",
    "    def indexcolumns(self,column):\n",
    "        type_col_index = list(column).index('type')\n",
    "        entity_col_index = list(column).index('Entity')\n",
    "        return type_col_index, entity_col_index\n",
    "    \n",
    "    def action_to_request(self,indice,current_state):\n",
    "        if indice is None or indice < 0 or indice >= current_state.shape[0] :\n",
    "            # print(f\"Indice negativo: {indice}\")\n",
    "            return None\n",
    "        element=None\n",
    "        for i in range(current_state.shape[0]):\n",
    "            if i == indice:\n",
    "                element=current_state[i, 0]\n",
    "                # print(f\"Elemento selezionato: {element}\")\n",
    "                break\n",
    "                \n",
    "        if element is not None:\n",
    "            row = lab.b_df.loc[lab.b_df['id'] == element]\n",
    "            if not row.empty:\n",
    "                values = row['Entity'].values[0]\n",
    "                return values   \n",
    "            else:\n",
    "        # print(f\"No entity found with id {element}\")\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def get_state(self,b_df,val=True):\n",
    "        machine_df=pd.DataFrame(self.env.log,columns=[\"ResourceName\",\"StateName\",\"timeIn\",\"timeOut\"])\n",
    "        machine_df=machine_df.loc[machine_df.ResourceName.isin([\"front\",\"drill\",\"robot\",\"camera\",\"back\",\"press\",\"manual\"])]\n",
    "        batch_df = b_df[b_df['Entity'].isin(lab.gate.Store.items)] # Filtra solo le righe del batch che sono presenti nello store\n",
    "        spazio_stati=self.concatenate_state_dataframes(batch_df,machine_df)\n",
    "        spazio_stati.to_excel('spazio_stati.xlsx')\n",
    "        spazio_stati,index = self.convertdataframe(spazio_stati,flag=False)\n",
    "        # print(spazio_stati.dtype)\n",
    "        if val:\n",
    "            return spazio_stati\n",
    "        else:\n",
    "            return spazio_stati, index\n",
    "\n",
    "\n",
    "#FINE AGGIUNTA\n",
    "    def build(self):\n",
    "        self.Store = pym.Store(self.env,self.capacity)\n",
    "        self.Messages = pym.Store(self.env)\n",
    "    def put(self,item):\n",
    "        return self.Store.put(item)\n",
    "    class Loading(State):\n",
    "        def _do(self):\n",
    "            # print('Load: %d' %self.sm.initialWIP)\n",
    "            self.sm.initialWIP -= 1\n",
    "            self.fw()\n",
    "    class Waiting(State):\n",
    "        initial_state = True\n",
    "        def _do(self):\n",
    "            self.sm.message = self.Messages.subscribe()\n",
    "            if self.sm.initialWIP > 0:\n",
    "                self.initial_timeout = self.env.timeout(1)\n",
    "            else:\n",
    "                self.initial_timeout = self.env.event()\n",
    "    class Forwarding(State):\n",
    "        def _do(self):\n",
    "            self.message.confirm()\n",
    "            if self.message.value == 'terminator':\n",
    "                self.sm.WIP -= 1\n",
    "                self.sm.WIPlist.append([self.env.now,self.WIP])\n",
    "                # print(self.sm.WIPlist)\n",
    "            self.FIFO()\n",
    "            self.CONWIP()\n",
    "    \n",
    "    def CONWIP(self):\n",
    "        if self.message.value == 'terminator':\n",
    "            self.fw()\n",
    "    def FIFO(self):\n",
    "        pass\n",
    "  \n",
    "    def fw(self):    \n",
    "        if self.request is None:\n",
    "            flag = 0\n",
    "            current_state, columns = self.get_state(lab.b_df, val=False)\n",
    "            type_col_index, entity_col_index = self.indexcolumns(columns)\n",
    "            action = self.dqn_agent.act(current_state, type_col_index, entity_col_index)\n",
    "            # print(action)  # index intero\n",
    "            actionselct = self.action_to_request(action, current_state)  # entity\n",
    "\n",
    "            if not self.Store:\n",
    "                flag = 1\n",
    "            if actionselct is not None:\n",
    "                self.request = self.Store.get(self.filtro(actionselct))\n",
    "                self.Next.put(self.request.value)\n",
    "                self.request = None\n",
    "                self.WIP += 1\n",
    "                self.WIPlist.append([self.env.now, self.WIP])\n",
    "\n",
    "            next_state = self.get_state(lab.b_df)\n",
    "            reward = self.dqn_agent.get_reward(current_state, columns, actionselct, flag,self.dones)\n",
    "            self.dqn_agent.remember(current_state, action, reward, next_state, self.dones)\n",
    "            self.step_count += 1\n",
    "            if len(self.dqn_agent.memory) > 5 and self.step_count % self.replay_frequency == 0:\n",
    "                self.dqn_agent.replay(3)\n",
    "        else:\n",
    "            pass\n",
    "    T0 = Transition(Waiting,Loading,lambda self: self.initial_timeout)\n",
    "    T1 = Transition(Waiting,Forwarding,lambda self: self.sm.message)\n",
    "    T2 = Transition(Loading,Waiting,None)\n",
    "    T3 = Transition(Forwarding,Waiting,None)\n",
    "         \n",
    "\n",
    "class Router(pym.Router):\n",
    "    def __deepcopy(self,memo):\n",
    "        super().deepcopy(self,memo)\n",
    "    def __init__(self, env, name=None):\n",
    "        super().__init__(env, name)\n",
    "        self.var.requestOut = []\n",
    "        self.var.sent = []\n",
    "        self.putEvent = env.event()\n",
    "    def build(self):\n",
    "        self.Queue = Box(self.env)\n",
    "    def condition_check(self,item,target):\n",
    "        return True\n",
    "    def put(self,item):\n",
    "        if self.putEvent.triggered:\n",
    "            self.putEvent.restart()\n",
    "        self.putEvent.succeed()\n",
    "        return self.Queue.put(item)\n",
    "    class Sending(State):\n",
    "        initial_state = True\n",
    "        def _do(self):\n",
    "            self.sm.putEvent.restart()\n",
    "            self.sm.var.requestIn = self.sm.putEvent\n",
    "            self.sm.var.requestOut = [item for sublist in [[next.subscribe(item) for next in self.sm.Next if self.sm.condition_check(item,next)] for item in self.sm.Queue.items] for item in sublist]\n",
    "            if self.sm.var.requestOut == []:\n",
    "                self.sm.var.requestOut.append(self.sm.var.requestIn)\n",
    "    S2S2 = Transition(Sending,Sending,lambda self:AnyOf(self.env,self.var.requestOut),condition=lambda self:self.var.requestOut != [])\n",
    "    def action2(self):\n",
    "        self.Queue._trigger_put(self.env.event())\n",
    "        if not hasattr(self.var.requestOut[0],'item'):\n",
    "            return\n",
    "        for request in self.var.requestOut:\n",
    "            if not request.item in self.Queue.items:\n",
    "                request.cancel()\n",
    "                continue\n",
    "            if request.triggered:\n",
    "                if request.check():\n",
    "                    request.confirm()\n",
    "                    self.Queue.forward(request.item)\n",
    "                    continue\n",
    "    S2S2._action = action2\n",
    "'''  \n",
    "from pymulate import RouterNew\n",
    "class Router(RouterNew):\n",
    "    def __init__(self, env, name=None):\n",
    "        capacity=1\n",
    "        super().__init__(env, name,capacity)\n",
    "'''\n",
    "class RobotSwitch1(Router):\n",
    "    def condition_check(self, item, target):\n",
    "        if item.require_robot:\n",
    "            item.rework = True\n",
    "        if item.require_robot and target.name == 'convRobot1S':\n",
    "            return True\n",
    "        elif not item.require_robot and target.name != 'convRobot1S':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "class RobotSwitch2(Router):\n",
    "    def condition_check(self, item, target):\n",
    "        if len(target.Next)<2:\n",
    "            item.rework = False\n",
    "            return True\n",
    "        else:\n",
    "            item.rework = True\n",
    "            return False    \n",
    "\n",
    "class CloseOutSwitch(Router):\n",
    "    def condition_check(self, item, target):\n",
    "        if item.ok and type(target) == Terminator:\n",
    "            return True\n",
    "        elif not item.ok and type(target) != Terminator:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "# class Conveyor(pym.ParallelServer):\n",
    "#     def __init__(self,env,name=None,serviceTime=None,serviceTimeFunction=None,capacity=1):\n",
    "#         self._capacity = capacity\n",
    "#         serviceTime = capacity*3.5\n",
    "#         super().__init__(env,name,serviceTime,serviceTimeFunction,capacity)\n",
    "class Conveyor(pym.Conveyor):\n",
    "    def __init__(self,env,name=None,capacity=3):\n",
    "        super().__init__(env,name,capacity,0.75)\n",
    "        \n",
    "def newDT():\n",
    "    lab = globals()['lab']\n",
    "    deepcopy(lab)\n",
    "\n",
    "\n",
    "def newEntity():\n",
    "    seed(time.time())\n",
    "    e = Entity()\n",
    "    e.serviceTime['front'] = 10.52\n",
    "    e.serviceTime['drill'] = choices([30, 40, 50, 20],weights=[5,30,30,35])[0]\n",
    "    e.serviceTime['robot'] = choices([0, 81, 105, 108 ,120],weights=[91,3,2,2,2])[0]\n",
    "    e.serviceTime['camera'] = 3.5+expovariate(1/7.1)\n",
    "    e.serviceTime['back'] = choices([3.5,10.57],weights=[0.1,0.9])[0]\n",
    "    if e.serviceTime['back']>0:\n",
    "        e.serviceTime['press'] = 3.5+expovariate(1/7.5)\n",
    "    else:\n",
    "        e.serviceTime['press'] = 3.5\n",
    "    e.serviceTime['manual'] = max(np.random.normal(9.2,2),0)\n",
    "    return e\n",
    "\n",
    "def batchCreate(seed=1,numJobs=10,return_both=False):\n",
    "    np.random.seed(seed)\n",
    "    jList = []\n",
    "    complist = []\n",
    "    while len(jList)<numJobs:\n",
    "        e=newEntity()\n",
    "        # num = round(np.random.triangular(1,numJobs/2,numJobs))\n",
    "        # # print(num)\n",
    "        # for i in range(num):\n",
    "        jList.append(e)\n",
    "        entity_info = {\n",
    "                'id': e.ID,\n",
    "                'Entity': e,\n",
    "                'serviceTime': e.serviceTime\n",
    "                }\n",
    "        complist.append(entity_info)\n",
    "        if len(jList)>=numJobs:  # l'ho aggiunto io per evitare che si creino più entità di quelle richieste\n",
    "            break\n",
    "    if return_both:\n",
    "        return jList, complist\n",
    "    else:\n",
    "        return jList\n",
    "    \n",
    "\n",
    "class Lab():\n",
    "    def __init__(self,b,maxtime):\n",
    "        conveyTime = 6\n",
    "        self.env = pym.Environment() #crea l'ambiente\n",
    "        # self.g = Generator(self.env) #genera un nuovo pezzo\n",
    "        \n",
    "        self.a=self.env.log  #ambiente stati macchine è un dataframe della lista self.state_log\n",
    "        self.machine_df=pd.DataFrame(self.a,columns=[\"ResourceName\",\"StateName\",\"timeIn\",\"timeOut\"])\n",
    "        self.machine_df=self.machine_df.loc[self.machine_df.ResourceName.isin([\"front\",\"drill\",\"robot\",\"camera\",\"back\",\"press\",\"manual\"])]\n",
    "        self.machine_df.to_excel('machine_df.xlsx')\n",
    "        \n",
    "        b_df = pd.DataFrame(b)\n",
    "        self.b_df=pd.concat([b_df['id'],b_df['Entity'], pd.DataFrame(b_df['serviceTime'].tolist())],axis=1)\n",
    "        self.b_df.to_excel('b_df.xlsx')\n",
    "        self.dim_state=self.b_df.shape[1]+self.machine_df.shape[1]+1 #14\n",
    "        self.dim_action=len(b_df) #come la capacity\n",
    "        self.list = []\n",
    "        self.gate = Gate(self.env,statedim=self.dim_state,actiondim=self.dim_action,max_time=maxtime) #crea il gate\n",
    "\n",
    "        # DR= despaching rule OR=order release \n",
    "        # self.conv1 = Conveyor(self.env,capacity=3)\n",
    "        self.conv1S = pym.Server(self.env,serviceTime=conveyTime) \n",
    "        self.conv1Q = pym.Queue(self.env,capacity=2)\n",
    "        self.front = LabServer(self.env,'front')\n",
    "        # self.conv2 = Conveyor(self.env,capacity=3)\n",
    "        self.conv2S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.conv2Q = pym.Queue(self.env,capacity=2)\n",
    "        self.drill = LabServer(self.env,'drill')\n",
    "        # self.conv3 = Conveyor(self.env,capacity=3)\n",
    "        self.conv3S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.conv3Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        \n",
    "        self.switch1 = RobotSwitch1(self.env)\n",
    "        # self.convRobot1 = Conveyor(self.env,'convRobot1',capacity=3)\n",
    "        self.convRobot1S = pym.Server(self.env,serviceTime=conveyTime,name='convRobot1S')\n",
    "        self.convRobot1Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        # self.bridge = Conveyor(self.env,capacity=3)\n",
    "        self.bridgeS = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.bridgeQ = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        # self.convRobot2 = Conveyor(self.env,'convRobot2',capacity=3)\n",
    "        self.convRobot2S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.convRobot2Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        self.switch2 = RobotSwitch2(self.env)\n",
    "        # self.convRobot3 = Conveyor(self.env,capacity=3)\n",
    "        self.convRobot3S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.convRobot3Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        self.robot = LabServer(self.env,'robot')\n",
    "        # self.convRobotOut = Conveyor(self.env,capacity=3)\n",
    "        self.convRobotOutS = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.convRobotOutQ = pym.Queue(self.env,capacity=2)\n",
    "        # self.conv5 = Conveyor(self.env,capacity=3)\n",
    "        self.conv5S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.conv5Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        self.camera = LabServer(self.env,'camera')\n",
    "        # self.conv6 = Conveyor(self.env,capacity=3)\n",
    "        self.conv6S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.conv6Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        self.back = LabServer(self.env,'back')\n",
    "        # self.conv7 = Conveyor(self.env,capacity=3)\n",
    "        self.conv7S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.conv7Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        self.press = LabServer(self.env,'press')\n",
    "        # self.conv8 = Conveyor(self.env,capacity=3)\n",
    "        self.conv8S = pym.Server(self.env,serviceTime=conveyTime)\n",
    "        self.conv8Q = pym.Queue(self.env,capacity=2)\n",
    "\n",
    "        self.manual = LabServer(self.env,'manual')\n",
    "        self.outSwitch = CloseOutSwitch(self.env)\n",
    "        self.terminator = Terminator(self.env)\n",
    "        \n",
    "        # self.g.Next = self.gate\n",
    "        self.gate.Next = self.conv1S\n",
    "        \n",
    "        # self.conv1.Next = self.front\n",
    "        self.conv1S.Next = self.conv1Q\n",
    "        self.conv1Q.Next = self.front\n",
    "\n",
    "        self.front.Next = self.conv2S\n",
    "        # self.conv2.Next = self.drill\n",
    "        self.conv2S.Next = self.conv2Q\n",
    "        self.conv2Q.Next = self.drill\n",
    "        self.drill.Next = self.conv3S\n",
    "        self.conv3S.Next = self.conv3Q\n",
    "        self.conv3Q.Next = self.switch1\n",
    "        # self.conv3.Next = self.switch1\n",
    "        \n",
    "        self.switch1.Next = [self.convRobot1S,self.bridgeS]\n",
    "        self.convRobot1S.Next = self.convRobot1Q\n",
    "        self.convRobot1Q.Next = self.switch2\n",
    "\n",
    "        self.switch2.Next = [self.convRobot2S,self.convRobot3S]\n",
    "        self.convRobot2S.Next = self.convRobot2Q\n",
    "        self.convRobot2Q.Next = self.robot\n",
    "\n",
    "        self.convRobot3S.Next = self.convRobot3Q\n",
    "        self.convRobot3Q.Next = self.convRobotOutS\n",
    "\n",
    "        self.robot.Next = self.convRobotOutS\n",
    "        self.convRobotOutS.Next = self.convRobotOutQ\n",
    "\n",
    "        self.convRobotOutQ.Next = self.conv5S\n",
    "        self.bridgeS.Next = self.bridgeQ\n",
    "        self.bridgeQ.Next = self.conv5S\n",
    "\n",
    "        \n",
    "        self.conv5S.Next = self.conv5Q\n",
    "        self.conv5Q.Next = self.camera\n",
    "\n",
    "        self.camera.Next = self.conv6S\n",
    "        self.conv6S.Next = self.conv6Q\n",
    "        self.conv6Q.Next = self.back\n",
    "\n",
    "        self.back.Next = self.conv7S\n",
    "        self.conv7S.Next = self.conv7Q\n",
    "        self.conv7Q.Next = self.press\n",
    "\n",
    "        self.press.Next = self.conv8S\n",
    "        self.conv8S.Next = self.conv8Q\n",
    "        self.conv8Q.Next = self.manual\n",
    "\n",
    "        self.manual.Next = self.outSwitch\n",
    "        self.outSwitch.Next = [self.conv1S,self.terminator]\n",
    "        \n",
    "        for x in [self.front,self.drill,self.robot,self.camera,self.back,self.press,self.manual]:\n",
    "            x.controller = self.gate\n",
    "        self.terminator.controller = self.gate\n",
    "        self.gate.lab = self\n",
    "\n",
    "       \n",
    "\n",
    "    def run(self,Tend):\n",
    "        self.env.run(Tend)\n",
    "        if self.gate.dqn_agent.isdone(self.env):\n",
    "            self.gate.dqn_agent.update_last_transition()\n",
    "            print(\"Operazione completata\")\n",
    "        else:\n",
    "            print(\"Operazione non completata\")\n",
    "        \n",
    "       #return pd.DataFrame(self.env.state_log)\n",
    "        return self.env.state_log\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello esistente trovato al ciclo 0.\n",
      "No saved model found, starting with a new model\n",
      "Not enough episodes in memory to replay.\n",
      "Not enough episodes in memory to replay.\n",
      "Simulation finished\n",
      "Final reward: -555.8136889395084\n",
      "Model saved to dqn_model.pth\n",
      "Operazione completata\n",
      "Model saved correctly\n",
      "Model loaded from dqn_model.pth\n",
      "Not enough episodes in memory to replay.\n",
      "Not enough episodes in memory to replay.\n",
      "Simulation finished\n",
      "Final reward: -493.7411653008901\n",
      "Model saved to dqn_model.pth\n",
      "Operazione completata\n",
      "Model saved correctly\n",
      "Model loaded from dqn_model.pth\n",
      "Not enough episodes in memory to replay.\n",
      "Not enough episodes in memory to replay.\n",
      "Simulation finished\n",
      "Final reward: -601.6132600569114\n",
      "Model saved to dqn_model.pth\n",
      "Operazione completata\n",
      "Model saved correctly\n",
      "Model loaded from dqn_model.pth\n",
      "States tensor shapes: [torch.Size([17, 14]), torch.Size([16, 14]), torch.Size([15, 14]), torch.Size([14, 14]), torch.Size([13, 14]), torch.Size([12, 14]), torch.Size([11, 14]), torch.Size([11, 14]), torch.Size([10, 14]), torch.Size([9, 14]), torch.Size([8, 14]), torch.Size([8, 14]), torch.Size([46, 14]), torch.Size([64, 14]), torch.Size([82, 14]), torch.Size([102, 14]), torch.Size([116, 14]), torch.Size([131, 14]), torch.Size([146, 14]), torch.Size([161, 14]), torch.Size([175, 14]), torch.Size([186, 14])]\n",
      "Next states tensor shapes: [torch.Size([16, 14]), torch.Size([15, 14]), torch.Size([14, 14]), torch.Size([13, 14]), torch.Size([12, 14]), torch.Size([11, 14]), torch.Size([10, 14]), torch.Size([10, 14]), torch.Size([9, 14]), torch.Size([8, 14]), torch.Size([8, 14]), torch.Size([8, 14]), torch.Size([46, 14]), torch.Size([64, 14]), torch.Size([82, 14]), torch.Size([102, 14]), torch.Size([116, 14]), torch.Size([131, 14]), torch.Size([146, 14]), torch.Size([161, 14]), torch.Size([175, 14]), torch.Size([186, 14])]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [16] at entry 0 and [15] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m lab\u001b[38;5;241m.\u001b[39mgate\u001b[38;5;241m.\u001b[39mdqn_agent\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel not loaded correctly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mlab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(lab\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstate_log, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResource\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResourceName\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mState\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStateName\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeIn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeOut\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     25\u001b[0m df\u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[df\u001b[38;5;241m.\u001b[39mResourceName\u001b[38;5;241m.\u001b[39misin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfront\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrill\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrobot\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcamera\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpress\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanual\u001b[39m\u001b[38;5;124m\"\u001b[39m])]\n",
      "Cell \u001b[1;32mIn[1], line 1001\u001b[0m, in \u001b[0;36mLab.run\u001b[1;34m(self, Tend)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m,Tend):\n\u001b[1;32m-> 1001\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate\u001b[38;5;241m.\u001b[39mdqn_agent\u001b[38;5;241m.\u001b[39misdone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv):\n\u001b[0;32m   1003\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate\u001b[38;5;241m.\u001b[39mdqn_agent\u001b[38;5;241m.\u001b[39mupdate_last_transition()\n",
      "File \u001b[1;32mc:\\Users\\Utente\\GitHub\\hsim\\hsim\\core\\core.py:43\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[1;34m(self, until)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m <= \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (current time) --> executing until \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m(at, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnow, at\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnow))\n\u001b[0;32m     42\u001b[0m     at \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnow\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utente\\GitHub\\hsim\\.venv\\Lib\\site-packages\\simpy\\core.py:246\u001b[0m, in \u001b[0;36mEnvironment.run\u001b[1;34m(self, until)\u001b[0m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 246\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m StopSimulation \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# == until.value\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utente\\GitHub\\hsim\\hsim\\core\\core.py:62\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_queue[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 62\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Utente\\GitHub\\hsim\\.venv\\Lib\\site-packages\\simpy\\core.py:196\u001b[0m, in \u001b[0;36mEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m callbacks, event\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m event\u001b[38;5;241m.\u001b[39mcallbacks, \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m callbacks:\n\u001b[1;32m--> 196\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m event\u001b[38;5;241m.\u001b[39m_ok \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(event, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_defused\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;66;03m# The event has failed and has not been defused. Crash the\u001b[39;00m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# environment.\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# Create a copy of the failure exception with a new traceback.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(event\u001b[38;5;241m.\u001b[39m_value)(\u001b[38;5;241m*\u001b[39mevent\u001b[38;5;241m.\u001b[39m_value\u001b[38;5;241m.\u001b[39margs)\n",
      "File \u001b[1;32mc:\\Users\\Utente\\GitHub\\hsim\\hsim\\core\\chfsm.py:268\u001b[0m, in \u001b[0;36mState._resume\u001b[1;34m(self, event)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39m_active_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event,Initialize):\n\u001b[1;32m--> 268\u001b[0m     \u001b[43mmethod_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    269\u001b[0m     events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m transition \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transitions:\n\u001b[0;32m    271\u001b[0m         \u001b[38;5;66;03m# transition._state = self\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Utente\\GitHub\\hsim\\hsim\\core\\core.py:108\u001b[0m, in \u001b[0;36mmethod_lambda\u001b[1;34m(self, function)\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 676\u001b[0m, in \u001b[0;36mGate.Loading._do\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_do\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;66;03m# print('Load: %d' %self.sm.initialWIP)\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msm\u001b[38;5;241m.\u001b[39minitialWIP \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 676\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 724\u001b[0m, in \u001b[0;36mGate.fw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdqn_agent\u001b[38;5;241m.\u001b[39mmemory) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_count \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplay_frequency \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 724\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdqn_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 460\u001b[0m, in \u001b[0;36mDQNAgent.replay\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    457\u001b[0m non_final_next_states \u001b[38;5;241m=\u001b[39m [next_states[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(next_states)) \u001b[38;5;28;01mif\u001b[39;00m non_final_mask[i]]\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_final_next_states) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 460\u001b[0m     next_q_values \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnon_final_next_states\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m     targets[non_final_mask] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m next_q_values\n\u001b[0;32m    463\u001b[0m final_reward \u001b[38;5;241m=\u001b[39m rewards[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [16] at entry 0 and [15] at entry 1"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "Entity.reset_id_counter()\n",
    "\n",
    "makespan=list(pd.read_excel('makespan.xlsx')['Makespan'])\n",
    "for i in range(10):\n",
    "    Entity.reset_id_counter()\n",
    "    model_path = 'dqn_model.pth'\n",
    "    if i == 0:\n",
    "        if os.path.exists(model_path):\n",
    "            print(f\"Modello esistente trovato al ciclo {i}.\")\n",
    "            os.remove(model_path)\n",
    "        else:\n",
    "            print(f\"Nessun modello esistente trovato al ciclo {i}. Inizio con un nuovo modello.\")     #     \n",
    "    s,b = batchCreate(0,numJobs=10,return_both=True)\n",
    "    \n",
    "    lab=Lab(b,1100)\n",
    "    # lab.gate.Store.items = [item['Entity'] for item in b]\n",
    "    lab.gate.Store.items= copy.copy(s)\n",
    "    if i > 0:\n",
    "        assert lab.gate.dqn_agent.model is not None, \"Model not loaded correctly\"\n",
    "    lab.run(1100)\n",
    "\n",
    "    df = pd.DataFrame(lab.env.state_log, columns=[\"Resource\",\"ResourceName\",\"State\",\"StateName\",\"Entity\",\"?\",\"timeIn\",\"timeOut\"])\n",
    "    df= df.loc[df.ResourceName.isin([\"front\",\"drill\",\"robot\",\"camera\",\"back\",\"press\",\"manual\"])]\n",
    "    mks=df.timeOut.max()-df.timeIn.min()\n",
    "\n",
    "    makespan.append(mks)\n",
    "    # Verifica che il modello sia stato salvato correttamente\n",
    "    try:\n",
    "        checkpoint = torch.load('dqn_model.pth')\n",
    "        assert 'model_state_dict' in checkpoint, \"Model state dict not found in checkpoint\"\n",
    "        print(\"Model saved correctly\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model not saved correctly\")\n",
    "\n",
    "\n",
    "file_path = 'makespan.xlsx'\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(file_path)\n",
    "\n",
    "mksdf = pd.DataFrame(makespan, columns=['Makespan'])\n",
    "mksdf.to_excel('makespan.xlsx')\n",
    "print(makespan)\n",
    "# Crea il grafico a linee\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(makespan, marker='o', linestyle='-', color='b', label='Makespan')\n",
    "\n",
    "# Aggiungi etichette e titolo\n",
    "plt.xlabel('Iterazione')\n",
    "plt.ylabel('Makespan (secondi)')\n",
    "plt.title('Variazione del Makespan nel Tempo')\n",
    "plt.legend()\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per cancellare i dati sull'excel se devo ricominciare\n",
    "import pandas as pd\n",
    "\n",
    "file_path = 'makespan.xlsx'\n",
    "\n",
    "# Crea un DataFrame vuoto con la colonna 'Makespan'\n",
    "df = pd.DataFrame(columns=['Makespan'])\n",
    "\n",
    "# Sovrascrivi il file Excel con il DataFrame vuoto\n",
    "df.to_excel(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "# Supponiamo che lab.gate.dqn_agent.memory sia un deque di transizioni\n",
    "c = deepcopy(lab.gate.dqn_agent.memory)\n",
    "\n",
    "# Converti il deque in una lista di dizionari\n",
    "memory_list = []\n",
    "for transition in c:\n",
    "    state = transition[0].tolist() if isinstance(transition[0], np.ndarray) else list(transition[0])\n",
    "    next_state = transition[3].tolist() if isinstance(transition[3], np.ndarray) else list(transition[3])\n",
    "    memory_list.append({\n",
    "        'state': state,\n",
    "        'action': transition[1],\n",
    "        'reward': transition[2],\n",
    "        'next_state': next_state,\n",
    "        'done': transition[4]\n",
    "    })\n",
    "\n",
    "# Converti la lista di dizionari in un DataFrame di pandas\n",
    "df = pd.DataFrame(memory_list)\n",
    "\n",
    "# Scrivi il DataFrame su un file Excel\n",
    "df.to_excel('dqn_memory.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = len(self.memory)\n",
    "num_columns = 0\n",
    "\n",
    "if num_rows > 0:\n",
    "    first_sequence = self.memory[0]\n",
    "    if len(first_sequence) > 0:\n",
    "        first_transition = first_sequence[0]\n",
    "        num_columns = len(first_transition)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
